{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66909997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n",
      "top-level keys: ['embedding_layer.weight', 'unembed.weight', 'blocks.0.pre_norm.scale', 'blocks.0.post_norm.scale', 'blocks.0.projections.weight', 'blocks.0.projections._extra_state', 'blocks.0.filter.short_filter_weight', 'blocks.0.out_filter_dense.weight', 'blocks.0.out_filter_dense.bias', 'blocks.0.mlp.l1.weight', 'blocks.0.mlp.l2.weight', 'blocks.0.mlp.l3.weight', 'blocks.0.filter.h', 'blocks.1.pre_norm.scale', 'blocks.1.post_norm.scale', 'blocks.1.projections.weight', 'blocks.1.projections._extra_state', 'blocks.1.filter.short_filter_weight', 'blocks.1.filter.D', 'blocks.1.filter.h', 'blocks.1.out_filter_dense.weight', 'blocks.1.out_filter_dense.bias', 'blocks.1.mlp.l1.weight', 'blocks.1.mlp.l2.weight', 'blocks.1.mlp.l3.weight', 'blocks.2.pre_norm.scale', 'blocks.2.post_norm.scale', 'blocks.2.projections.weight', 'blocks.2.projections._extra_state', 'blocks.2.filter.short_filter_weight', 'blocks.2.filter.D', 'blocks.2.out_filter_dense.weight', 'blocks.2.out_filter_dense.bias', 'blocks.2.mlp.l1.weight', 'blocks.2.mlp.l2.weight', 'blocks.2.mlp.l3.weight', 'blocks.2.filter.log_poles', 'blocks.2.filter.residues', 'blocks.3.pre_norm.scale', 'blocks.3.post_norm.scale', 'blocks.3.inner_mha_cls.Wqkv.weight', 'blocks.3.inner_mha_cls.rotary_emb.inv_freq', 'blocks.3.inner_mha_cls.out_proj.weight', 'blocks.3.inner_mha_cls.out_proj.bias', 'blocks.3.mixer.dense._extra_state', 'blocks.3.mlp.l1.weight', 'blocks.3.mlp.l2.weight', 'blocks.3.mlp.l3.weight', 'blocks.4.pre_norm.scale', 'blocks.4.post_norm.scale', 'blocks.4.projections.weight', 'blocks.4.projections._extra_state', 'blocks.4.filter.short_filter_weight', 'blocks.4.out_filter_dense.weight', 'blocks.4.out_filter_dense.bias', 'blocks.4.mlp.l1.weight', 'blocks.4.mlp.l2.weight', 'blocks.4.mlp.l3.weight', 'blocks.4.filter.h', 'blocks.5.pre_norm.scale', 'blocks.5.post_norm.scale', 'blocks.5.projections.weight', 'blocks.5.projections._extra_state', 'blocks.5.filter.short_filter_weight', 'blocks.5.filter.D', 'blocks.5.filter.h', 'blocks.5.out_filter_dense.weight', 'blocks.5.out_filter_dense.bias', 'blocks.5.mlp.l1.weight', 'blocks.5.mlp.l2.weight', 'blocks.5.mlp.l3.weight', 'blocks.6.pre_norm.scale', 'blocks.6.post_norm.scale', 'blocks.6.projections.weight', 'blocks.6.projections._extra_state', 'blocks.6.filter.short_filter_weight', 'blocks.6.filter.D', 'blocks.6.out_filter_dense.weight', 'blocks.6.out_filter_dense.bias', 'blocks.6.mlp.l1.weight', 'blocks.6.mlp.l2.weight', 'blocks.6.mlp.l3.weight', 'blocks.6.filter.log_poles', 'blocks.6.filter.residues', 'blocks.7.pre_norm.scale', 'blocks.7.post_norm.scale', 'blocks.7.projections.weight', 'blocks.7.projections._extra_state', 'blocks.7.filter.short_filter_weight', 'blocks.7.out_filter_dense.weight', 'blocks.7.out_filter_dense.bias', 'blocks.7.mlp.l1.weight', 'blocks.7.mlp.l2.weight', 'blocks.7.mlp.l3.weight', 'blocks.7.filter.h', 'blocks.8.pre_norm.scale', 'blocks.8.post_norm.scale', 'blocks.8.projections.weight', 'blocks.8.projections._extra_state', 'blocks.8.filter.short_filter_weight']\n",
      "Some tensor params:\n",
      " 0 embedding_layer.weight                             (512, 4096) torch.bfloat16\n",
      " 1 unembed.weight                                     (512, 4096) torch.bfloat16\n",
      " 2 blocks.0.pre_norm.scale                            (4096,) torch.bfloat16\n",
      " 3 blocks.0.post_norm.scale                           (4096,) torch.bfloat16\n",
      " 4 blocks.0.projections.weight                        (12288, 4096) torch.bfloat16\n",
      " 5 blocks.0.filter.short_filter_weight                (12288, 1, 3) torch.bfloat16\n",
      " 6 blocks.0.out_filter_dense.weight                   (4096, 4096) torch.bfloat16\n",
      " 7 blocks.0.out_filter_dense.bias                     (4096,) torch.bfloat16\n",
      " 8 blocks.0.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      " 9 blocks.0.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "10 blocks.0.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "11 blocks.0.filter.h                                  (256, 1, 7) torch.bfloat16\n",
      "12 blocks.1.pre_norm.scale                            (4096,) torch.bfloat16\n",
      "13 blocks.1.post_norm.scale                           (4096,) torch.bfloat16\n",
      "14 blocks.1.projections.weight                        (12288, 4096) torch.bfloat16\n",
      "15 blocks.1.filter.short_filter_weight                (12288, 1, 3) torch.bfloat16\n",
      "16 blocks.1.filter.D                                  (4096,) torch.bfloat16\n",
      "17 blocks.1.filter.h                                  (256, 1, 128) torch.bfloat16\n",
      "18 blocks.1.out_filter_dense.weight                   (4096, 4096) torch.bfloat16\n",
      "19 blocks.1.out_filter_dense.bias                     (4096,) torch.bfloat16\n",
      "20 blocks.1.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      "21 blocks.1.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "22 blocks.1.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "23 blocks.2.pre_norm.scale                            (4096,) torch.bfloat16\n",
      "24 blocks.2.post_norm.scale                           (4096,) torch.bfloat16\n",
      "25 blocks.2.projections.weight                        (12288, 4096) torch.bfloat16\n",
      "26 blocks.2.filter.short_filter_weight                (12288, 1, 3) torch.bfloat16\n",
      "27 blocks.2.filter.D                                  (4096,) torch.bfloat16\n",
      "28 blocks.2.out_filter_dense.weight                   (4096, 4096) torch.bfloat16\n",
      "29 blocks.2.out_filter_dense.bias                     (4096,) torch.bfloat16\n",
      "30 blocks.2.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      "31 blocks.2.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "32 blocks.2.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "33 blocks.2.filter.log_poles                          (4096, 16, 1) torch.float32\n",
      "34 blocks.2.filter.residues                           (4096, 16) torch.float32\n",
      "35 blocks.3.pre_norm.scale                            (4096,) torch.bfloat16\n",
      "36 blocks.3.post_norm.scale                           (4096,) torch.bfloat16\n",
      "37 blocks.3.inner_mha_cls.Wqkv.weight                 (12288, 4096) torch.bfloat16\n",
      "38 blocks.3.inner_mha_cls.rotary_emb.inv_freq         (64,) torch.bfloat16\n",
      "39 blocks.3.inner_mha_cls.out_proj.weight             (4096, 4096) torch.bfloat16\n",
      "40 blocks.3.inner_mha_cls.out_proj.bias               (4096,) torch.bfloat16\n",
      "41 blocks.3.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      "42 blocks.3.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "43 blocks.3.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "44 blocks.4.pre_norm.scale                            (4096,) torch.bfloat16\n",
      "45 blocks.4.post_norm.scale                           (4096,) torch.bfloat16\n",
      "46 blocks.4.projections.weight                        (12288, 4096) torch.bfloat16\n",
      "47 blocks.4.filter.short_filter_weight                (12288, 1, 3) torch.bfloat16\n",
      "48 blocks.4.out_filter_dense.weight                   (4096, 4096) torch.bfloat16\n",
      "49 blocks.4.out_filter_dense.bias                     (4096,) torch.bfloat16\n",
      "50 blocks.4.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      "51 blocks.4.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "52 blocks.4.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "53 blocks.4.filter.h                                  (256, 1, 7) torch.bfloat16\n",
      "54 blocks.5.pre_norm.scale                            (4096,) torch.bfloat16\n",
      "55 blocks.5.post_norm.scale                           (4096,) torch.bfloat16\n",
      "56 blocks.5.projections.weight                        (12288, 4096) torch.bfloat16\n",
      "57 blocks.5.filter.short_filter_weight                (12288, 1, 3) torch.bfloat16\n",
      "58 blocks.5.filter.D                                  (4096,) torch.bfloat16\n",
      "59 blocks.5.filter.h                                  (256, 1, 128) torch.bfloat16\n",
      "60 blocks.5.out_filter_dense.weight                   (4096, 4096) torch.bfloat16\n",
      "61 blocks.5.out_filter_dense.bias                     (4096,) torch.bfloat16\n",
      "62 blocks.5.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      "63 blocks.5.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "64 blocks.5.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "65 blocks.6.pre_norm.scale                            (4096,) torch.bfloat16\n",
      "66 blocks.6.post_norm.scale                           (4096,) torch.bfloat16\n",
      "67 blocks.6.projections.weight                        (12288, 4096) torch.bfloat16\n",
      "68 blocks.6.filter.short_filter_weight                (12288, 1, 3) torch.bfloat16\n",
      "69 blocks.6.filter.D                                  (4096,) torch.bfloat16\n",
      "70 blocks.6.out_filter_dense.weight                   (4096, 4096) torch.bfloat16\n",
      "71 blocks.6.out_filter_dense.bias                     (4096,) torch.bfloat16\n",
      "72 blocks.6.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      "73 blocks.6.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "74 blocks.6.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "75 blocks.6.filter.log_poles                          (4096, 16, 1) torch.float32\n",
      "76 blocks.6.filter.residues                           (4096, 16) torch.float32\n",
      "77 blocks.7.pre_norm.scale                            (4096,) torch.bfloat16\n",
      "78 blocks.7.post_norm.scale                           (4096,) torch.bfloat16\n",
      "79 blocks.7.projections.weight                        (12288, 4096) torch.bfloat16\n",
      "80 blocks.7.filter.short_filter_weight                (12288, 1, 3) torch.bfloat16\n",
      "81 blocks.7.out_filter_dense.weight                   (4096, 4096) torch.bfloat16\n",
      "82 blocks.7.out_filter_dense.bias                     (4096,) torch.bfloat16\n",
      "83 blocks.7.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      "84 blocks.7.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "85 blocks.7.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "86 blocks.7.filter.h                                  (256, 1, 7) torch.bfloat16\n",
      "87 blocks.8.pre_norm.scale                            (4096,) torch.bfloat16\n",
      "88 blocks.8.post_norm.scale                           (4096,) torch.bfloat16\n",
      "89 blocks.8.projections.weight                        (12288, 4096) torch.bfloat16\n",
      "90 blocks.8.filter.short_filter_weight                (12288, 1, 3) torch.bfloat16\n",
      "91 blocks.8.filter.D                                  (4096,) torch.bfloat16\n",
      "92 blocks.8.filter.h                                  (256, 1, 128) torch.bfloat16\n",
      "93 blocks.8.out_filter_dense.weight                   (4096, 4096) torch.bfloat16\n",
      "94 blocks.8.out_filter_dense.bias                     (4096,) torch.bfloat16\n",
      "95 blocks.8.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      "96 blocks.8.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "97 blocks.8.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "98 blocks.9.pre_norm.scale                            (4096,) torch.bfloat16\n",
      "99 blocks.9.post_norm.scale                           (4096,) torch.bfloat16\n",
      "100 blocks.9.projections.weight                        (12288, 4096) torch.bfloat16\n",
      "101 blocks.9.filter.short_filter_weight                (12288, 1, 3) torch.bfloat16\n",
      "102 blocks.9.filter.D                                  (4096,) torch.bfloat16\n",
      "103 blocks.9.out_filter_dense.weight                   (4096, 4096) torch.bfloat16\n",
      "104 blocks.9.out_filter_dense.bias                     (4096,) torch.bfloat16\n",
      "105 blocks.9.mlp.l1.weight                             (11008, 4096) torch.bfloat16\n",
      "106 blocks.9.mlp.l2.weight                             (11008, 4096) torch.bfloat16\n",
      "107 blocks.9.mlp.l3.weight                             (4096, 11008) torch.bfloat16\n",
      "108 blocks.9.filter.log_poles                          (4096, 16, 1) torch.float32\n",
      "109 blocks.9.filter.residues                           (4096, 16) torch.float32\n",
      "110 blocks.10.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "111 blocks.10.post_norm.scale                          (4096,) torch.bfloat16\n",
      "112 blocks.10.inner_mha_cls.Wqkv.weight                (12288, 4096) torch.bfloat16\n",
      "113 blocks.10.inner_mha_cls.rotary_emb.inv_freq        (64,) torch.bfloat16\n",
      "114 blocks.10.inner_mha_cls.out_proj.weight            (4096, 4096) torch.bfloat16\n",
      "115 blocks.10.inner_mha_cls.out_proj.bias              (4096,) torch.bfloat16\n",
      "116 blocks.10.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "117 blocks.10.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "118 blocks.10.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "119 blocks.11.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "120 blocks.11.post_norm.scale                          (4096,) torch.bfloat16\n",
      "121 blocks.11.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "122 blocks.11.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "123 blocks.11.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "124 blocks.11.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "125 blocks.11.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "126 blocks.11.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "127 blocks.11.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "128 blocks.11.filter.h                                 (256, 1, 7) torch.bfloat16\n",
      "129 blocks.12.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "130 blocks.12.post_norm.scale                          (4096,) torch.bfloat16\n",
      "131 blocks.12.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "132 blocks.12.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "133 blocks.12.filter.D                                 (4096,) torch.bfloat16\n",
      "134 blocks.12.filter.h                                 (256, 1, 128) torch.bfloat16\n",
      "135 blocks.12.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "136 blocks.12.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "137 blocks.12.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "138 blocks.12.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "139 blocks.12.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "140 blocks.13.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "141 blocks.13.post_norm.scale                          (4096,) torch.bfloat16\n",
      "142 blocks.13.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "143 blocks.13.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "144 blocks.13.filter.D                                 (4096,) torch.bfloat16\n",
      "145 blocks.13.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "146 blocks.13.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "147 blocks.13.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "148 blocks.13.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "149 blocks.13.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "150 blocks.13.filter.log_poles                         (4096, 16, 1) torch.float32\n",
      "151 blocks.13.filter.residues                          (4096, 16) torch.float32\n",
      "152 blocks.14.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "153 blocks.14.post_norm.scale                          (4096,) torch.bfloat16\n",
      "154 blocks.14.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "155 blocks.14.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "156 blocks.14.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "157 blocks.14.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "158 blocks.14.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "159 blocks.14.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "160 blocks.14.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "161 blocks.14.filter.h                                 (256, 1, 7) torch.bfloat16\n",
      "162 blocks.15.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "163 blocks.15.post_norm.scale                          (4096,) torch.bfloat16\n",
      "164 blocks.15.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "165 blocks.15.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "166 blocks.15.filter.D                                 (4096,) torch.bfloat16\n",
      "167 blocks.15.filter.h                                 (256, 1, 128) torch.bfloat16\n",
      "168 blocks.15.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "169 blocks.15.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "170 blocks.15.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "171 blocks.15.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "172 blocks.15.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "173 blocks.16.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "174 blocks.16.post_norm.scale                          (4096,) torch.bfloat16\n",
      "175 blocks.16.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "176 blocks.16.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "177 blocks.16.filter.D                                 (4096,) torch.bfloat16\n",
      "178 blocks.16.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "179 blocks.16.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "180 blocks.16.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "181 blocks.16.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "182 blocks.16.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "183 blocks.16.filter.log_poles                         (4096, 16, 1) torch.float32\n",
      "184 blocks.16.filter.residues                          (4096, 16) torch.float32\n",
      "185 blocks.17.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "186 blocks.17.post_norm.scale                          (4096,) torch.bfloat16\n",
      "187 blocks.17.inner_mha_cls.Wqkv.weight                (12288, 4096) torch.bfloat16\n",
      "188 blocks.17.inner_mha_cls.rotary_emb.inv_freq        (64,) torch.bfloat16\n",
      "189 blocks.17.inner_mha_cls.out_proj.weight            (4096, 4096) torch.bfloat16\n",
      "190 blocks.17.inner_mha_cls.out_proj.bias              (4096,) torch.bfloat16\n",
      "191 blocks.17.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "192 blocks.17.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "193 blocks.17.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "194 blocks.18.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "195 blocks.18.post_norm.scale                          (4096,) torch.bfloat16\n",
      "196 blocks.18.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "197 blocks.18.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "198 blocks.18.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "199 blocks.18.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "200 blocks.18.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "201 blocks.18.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "202 blocks.18.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "203 blocks.18.filter.h                                 (256, 1, 7) torch.bfloat16\n",
      "204 blocks.19.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "205 blocks.19.post_norm.scale                          (4096,) torch.bfloat16\n",
      "206 blocks.19.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "207 blocks.19.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "208 blocks.19.filter.D                                 (4096,) torch.bfloat16\n",
      "209 blocks.19.filter.h                                 (256, 1, 128) torch.bfloat16\n",
      "210 blocks.19.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "211 blocks.19.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "212 blocks.19.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "213 blocks.19.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "214 blocks.19.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "215 blocks.20.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "216 blocks.20.post_norm.scale                          (4096,) torch.bfloat16\n",
      "217 blocks.20.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "218 blocks.20.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "219 blocks.20.filter.D                                 (4096,) torch.bfloat16\n",
      "220 blocks.20.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "221 blocks.20.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "222 blocks.20.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "223 blocks.20.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "224 blocks.20.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "225 blocks.20.filter.log_poles                         (4096, 16, 1) torch.float32\n",
      "226 blocks.20.filter.residues                          (4096, 16) torch.float32\n",
      "227 blocks.21.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "228 blocks.21.post_norm.scale                          (4096,) torch.bfloat16\n",
      "229 blocks.21.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "230 blocks.21.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "231 blocks.21.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "232 blocks.21.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "233 blocks.21.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "234 blocks.21.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "235 blocks.21.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "236 blocks.21.filter.h                                 (256, 1, 7) torch.bfloat16\n",
      "237 blocks.22.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "238 blocks.22.post_norm.scale                          (4096,) torch.bfloat16\n",
      "239 blocks.22.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "240 blocks.22.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "241 blocks.22.filter.D                                 (4096,) torch.bfloat16\n",
      "242 blocks.22.filter.h                                 (256, 1, 128) torch.bfloat16\n",
      "243 blocks.22.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "244 blocks.22.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "245 blocks.22.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "246 blocks.22.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "247 blocks.22.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "248 blocks.23.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "249 blocks.23.post_norm.scale                          (4096,) torch.bfloat16\n",
      "250 blocks.23.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "251 blocks.23.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "252 blocks.23.filter.D                                 (4096,) torch.bfloat16\n",
      "253 blocks.23.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "254 blocks.23.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "255 blocks.23.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "256 blocks.23.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "257 blocks.23.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "258 blocks.23.filter.log_poles                         (4096, 16, 1) torch.float32\n",
      "259 blocks.23.filter.residues                          (4096, 16) torch.float32\n",
      "260 blocks.24.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "261 blocks.24.post_norm.scale                          (4096,) torch.bfloat16\n",
      "262 blocks.24.inner_mha_cls.Wqkv.weight                (12288, 4096) torch.bfloat16\n",
      "263 blocks.24.inner_mha_cls.rotary_emb.inv_freq        (64,) torch.bfloat16\n",
      "264 blocks.24.inner_mha_cls.out_proj.weight            (4096, 4096) torch.bfloat16\n",
      "265 blocks.24.inner_mha_cls.out_proj.bias              (4096,) torch.bfloat16\n",
      "266 blocks.24.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "267 blocks.24.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "268 blocks.24.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "269 blocks.25.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "270 blocks.25.post_norm.scale                          (4096,) torch.bfloat16\n",
      "271 blocks.25.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "272 blocks.25.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "273 blocks.25.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "274 blocks.25.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "275 blocks.25.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "276 blocks.25.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "277 blocks.25.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "278 blocks.25.filter.h                                 (256, 1, 7) torch.bfloat16\n",
      "279 blocks.26.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "280 blocks.26.post_norm.scale                          (4096,) torch.bfloat16\n",
      "281 blocks.26.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "282 blocks.26.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "283 blocks.26.filter.D                                 (4096,) torch.bfloat16\n",
      "284 blocks.26.filter.h                                 (256, 1, 128) torch.bfloat16\n",
      "285 blocks.26.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "286 blocks.26.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "287 blocks.26.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "288 blocks.26.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "289 blocks.26.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "290 blocks.27.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "291 blocks.27.post_norm.scale                          (4096,) torch.bfloat16\n",
      "292 blocks.27.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "293 blocks.27.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "294 blocks.27.filter.D                                 (4096,) torch.bfloat16\n",
      "295 blocks.27.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "296 blocks.27.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "297 blocks.27.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "298 blocks.27.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "299 blocks.27.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "300 blocks.27.filter.log_poles                         (4096, 16, 1) torch.float32\n",
      "301 blocks.27.filter.residues                          (4096, 16) torch.float32\n",
      "302 blocks.28.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "303 blocks.28.post_norm.scale                          (4096,) torch.bfloat16\n",
      "304 blocks.28.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "305 blocks.28.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "306 blocks.28.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "307 blocks.28.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "308 blocks.28.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "309 blocks.28.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "310 blocks.28.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "311 blocks.28.filter.h                                 (256, 1, 7) torch.bfloat16\n",
      "312 blocks.29.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "313 blocks.29.post_norm.scale                          (4096,) torch.bfloat16\n",
      "314 blocks.29.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "315 blocks.29.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "316 blocks.29.filter.D                                 (4096,) torch.bfloat16\n",
      "317 blocks.29.filter.h                                 (256, 1, 128) torch.bfloat16\n",
      "318 blocks.29.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "319 blocks.29.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "320 blocks.29.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "321 blocks.29.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "322 blocks.29.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "323 blocks.30.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "324 blocks.30.post_norm.scale                          (4096,) torch.bfloat16\n",
      "325 blocks.30.projections.weight                       (12288, 4096) torch.bfloat16\n",
      "326 blocks.30.filter.short_filter_weight               (12288, 1, 3) torch.bfloat16\n",
      "327 blocks.30.filter.D                                 (4096,) torch.bfloat16\n",
      "328 blocks.30.out_filter_dense.weight                  (4096, 4096) torch.bfloat16\n",
      "329 blocks.30.out_filter_dense.bias                    (4096,) torch.bfloat16\n",
      "330 blocks.30.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "331 blocks.30.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "332 blocks.30.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "333 blocks.30.filter.log_poles                         (4096, 16, 1) torch.float32\n",
      "334 blocks.30.filter.residues                          (4096, 16) torch.float32\n",
      "335 blocks.31.pre_norm.scale                           (4096,) torch.bfloat16\n",
      "336 blocks.31.post_norm.scale                          (4096,) torch.bfloat16\n",
      "337 blocks.31.inner_mha_cls.Wqkv.weight                (12288, 4096) torch.bfloat16\n",
      "338 blocks.31.inner_mha_cls.rotary_emb.inv_freq        (64,) torch.bfloat16\n",
      "339 blocks.31.inner_mha_cls.out_proj.weight            (4096, 4096) torch.bfloat16\n",
      "340 blocks.31.inner_mha_cls.out_proj.bias              (4096,) torch.bfloat16\n",
      "341 blocks.31.mlp.l1.weight                            (11008, 4096) torch.bfloat16\n",
      "342 blocks.31.mlp.l2.weight                            (11008, 4096) torch.bfloat16\n",
      "343 blocks.31.mlp.l3.weight                            (4096, 11008) torch.bfloat16\n",
      "344 norm.scale                                         (4096,) torch.bfloat16\n",
      "\n",
      "Non-tensor entries (inspect/ignore):\n",
      " 0 blocks.0.projections._extra_state                  BytesIO\n",
      " 1 blocks.1.projections._extra_state                  BytesIO\n",
      " 2 blocks.2.projections._extra_state                  BytesIO\n",
      " 3 blocks.3.mixer.dense._extra_state                  BytesIO\n",
      " 4 blocks.4.projections._extra_state                  BytesIO\n",
      " 5 blocks.5.projections._extra_state                  BytesIO\n",
      " 6 blocks.6.projections._extra_state                  BytesIO\n",
      " 7 blocks.7.projections._extra_state                  BytesIO\n",
      " 8 blocks.8.projections._extra_state                  BytesIO\n",
      " 9 blocks.9.projections._extra_state                  BytesIO\n",
      "10 blocks.10.mixer.dense._extra_state                 BytesIO\n",
      "11 blocks.11.projections._extra_state                 BytesIO\n",
      "12 blocks.12.projections._extra_state                 BytesIO\n",
      "13 blocks.13.projections._extra_state                 BytesIO\n",
      "14 blocks.14.projections._extra_state                 BytesIO\n"
     ]
    }
   ],
   "source": [
    "import torch, _io\n",
    "from torch.serialization import add_safe_globals\n",
    "\n",
    "# allow the specific global the checkpoint needs\n",
    "add_safe_globals([_io.BytesIO])\n",
    "\n",
    "ckpt = torch.load(\"../../models/evo2_7b_base.pt\",\n",
    "                  map_location=\"cpu\",   # safer to load on CPU first\n",
    "                  weights_only=True,    # stays in the \"safe\" path\n",
    "                  mmap=True)            # speed / lower RAM if on local disk\n",
    "\n",
    "print(type(ckpt))\n",
    "if isinstance(ckpt, dict):\n",
    "    print(\"top-level keys:\", list(ckpt.keys())[:100])\n",
    "\n",
    "# many checkpoints are either a state_dict directly or wrap it\n",
    "state_dict = ckpt.get(\"state_dict\", ckpt)\n",
    "\n",
    "sd = state_dict  # from your load\n",
    "\n",
    "tensor_rows = []\n",
    "non_tensor_rows = []\n",
    "\n",
    "for k, v in sd.items():\n",
    "    if torch.is_tensor(v):\n",
    "        tensor_rows.append((k, tuple(v.shape), v.dtype))\n",
    "    else:\n",
    "        non_tensor_rows.append((k, type(v).__name__))\n",
    "\n",
    "print(\"Some tensor params:\")\n",
    "for i, (k, shp, dt) in enumerate(tensor_rows):\n",
    "    print(f\"{i:2d} {k:50s} {shp} {dt}\")\n",
    "\n",
    "print(\"\\nNon-tensor entries (inspect/ignore):\")\n",
    "for i, (k, tname) in enumerate(non_tensor_rows[:15]):\n",
    "    print(f\"{i:2d} {k:50s} {tname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6959bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL PARAMETER SUMMARY ===\n",
      "Total tensor params: 6B\n",
      "Embeddings+Unembed: 4M\n",
      "  - embedding_layer.weight                        (512, 4096)  (2M)\n",
      "  - unembed.weight                                (512, 4096)  (2M)\n",
      "\n",
      "=== PER-BLOCK BREAKDOWN ===\n",
      "\n",
      "Block  0  [short_filter]  —  202M params\n",
      "   • blocks.0.projections.weight                   (12288, 4096)  (50M)\n",
      "   • blocks.0.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.0.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.0.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.0.out_filter_dense.weight              (4096, 4096)  (17M)\n",
      "   • blocks.0.filter.short_filter_weight           (12288, 1, 3)  (37K)\n",
      "\n",
      "Block  1  [long_filter]  —  202M params\n",
      "   • blocks.1.projections.weight                   (12288, 4096)  (50M)\n",
      "   • blocks.1.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.1.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.1.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.1.out_filter_dense.weight              (4096, 4096)  (17M)\n",
      "   • blocks.1.filter.short_filter_weight           (12288, 1, 3)  (37K)\n",
      "\n",
      "Block  2  [ssm]  —  203M params\n",
      "   • blocks.2.projections.weight                   (12288, 4096)  (50M)\n",
      "   • blocks.2.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.2.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.2.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.2.out_filter_dense.weight              (4096, 4096)  (17M)\n",
      "   • blocks.2.filter.log_poles                     (4096, 16, 1)  (66K)\n",
      "\n",
      "Block  3  [attention]  —  202M params\n",
      "   • blocks.3.inner_mha_cls.Wqkv.weight            (12288, 4096)  (50M)\n",
      "   • blocks.3.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.3.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.3.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.3.inner_mha_cls.out_proj.weight        (4096, 4096)  (17M)\n",
      "   • blocks.3.pre_norm.scale                       (4096,)  (4K)\n",
      "\n",
      "Block  4  [short_filter]  —  202M params\n",
      "   • blocks.4.projections.weight                   (12288, 4096)  (50M)\n",
      "   • blocks.4.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.4.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.4.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.4.out_filter_dense.weight              (4096, 4096)  (17M)\n",
      "   • blocks.4.filter.short_filter_weight           (12288, 1, 3)  (37K)\n",
      "\n",
      "Block  5  [long_filter]  —  202M params\n",
      "   • blocks.5.projections.weight                   (12288, 4096)  (50M)\n",
      "   • blocks.5.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.5.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.5.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.5.out_filter_dense.weight              (4096, 4096)  (17M)\n",
      "   • blocks.5.filter.short_filter_weight           (12288, 1, 3)  (37K)\n",
      "\n",
      "Block  6  [ssm]  —  203M params\n",
      "   • blocks.6.projections.weight                   (12288, 4096)  (50M)\n",
      "   • blocks.6.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.6.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.6.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.6.out_filter_dense.weight              (4096, 4096)  (17M)\n",
      "   • blocks.6.filter.log_poles                     (4096, 16, 1)  (66K)\n",
      "\n",
      "Block  7  [short_filter]  —  202M params\n",
      "   • blocks.7.projections.weight                   (12288, 4096)  (50M)\n",
      "   • blocks.7.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.7.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.7.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.7.out_filter_dense.weight              (4096, 4096)  (17M)\n",
      "   • blocks.7.filter.short_filter_weight           (12288, 1, 3)  (37K)\n",
      "\n",
      "Block  8  [long_filter]  —  202M params\n",
      "   • blocks.8.projections.weight                   (12288, 4096)  (50M)\n",
      "   • blocks.8.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.8.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.8.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.8.out_filter_dense.weight              (4096, 4096)  (17M)\n",
      "   • blocks.8.filter.short_filter_weight           (12288, 1, 3)  (37K)\n",
      "\n",
      "Block  9  [ssm]  —  203M params\n",
      "   • blocks.9.projections.weight                   (12288, 4096)  (50M)\n",
      "   • blocks.9.mlp.l1.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.9.mlp.l2.weight                        (11008, 4096)  (45M)\n",
      "   • blocks.9.mlp.l3.weight                        (4096, 11008)  (45M)\n",
      "   • blocks.9.out_filter_dense.weight              (4096, 4096)  (17M)\n",
      "   • blocks.9.filter.log_poles                     (4096, 16, 1)  (66K)\n",
      "\n",
      "Block 10  [attention]  —  202M params\n",
      "   • blocks.10.inner_mha_cls.Wqkv.weight           (12288, 4096)  (50M)\n",
      "   • blocks.10.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.10.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.10.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.10.inner_mha_cls.out_proj.weight       (4096, 4096)  (17M)\n",
      "   • blocks.10.pre_norm.scale                      (4096,)  (4K)\n",
      "\n",
      "Block 11  [short_filter]  —  202M params\n",
      "   • blocks.11.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.11.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.11.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.11.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.11.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.11.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 12  [long_filter]  —  202M params\n",
      "   • blocks.12.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.12.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.12.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.12.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.12.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.12.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 13  [ssm]  —  203M params\n",
      "   • blocks.13.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.13.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.13.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.13.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.13.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.13.filter.log_poles                    (4096, 16, 1)  (66K)\n",
      "\n",
      "Block 14  [short_filter]  —  202M params\n",
      "   • blocks.14.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.14.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.14.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.14.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.14.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.14.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 15  [long_filter]  —  202M params\n",
      "   • blocks.15.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.15.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.15.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.15.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.15.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.15.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 16  [ssm]  —  203M params\n",
      "   • blocks.16.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.16.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.16.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.16.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.16.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.16.filter.log_poles                    (4096, 16, 1)  (66K)\n",
      "\n",
      "Block 17  [attention]  —  202M params\n",
      "   • blocks.17.inner_mha_cls.Wqkv.weight           (12288, 4096)  (50M)\n",
      "   • blocks.17.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.17.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.17.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.17.inner_mha_cls.out_proj.weight       (4096, 4096)  (17M)\n",
      "   • blocks.17.pre_norm.scale                      (4096,)  (4K)\n",
      "\n",
      "Block 18  [short_filter]  —  202M params\n",
      "   • blocks.18.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.18.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.18.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.18.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.18.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.18.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 19  [long_filter]  —  202M params\n",
      "   • blocks.19.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.19.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.19.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.19.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.19.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.19.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 20  [ssm]  —  203M params\n",
      "   • blocks.20.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.20.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.20.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.20.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.20.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.20.filter.log_poles                    (4096, 16, 1)  (66K)\n",
      "\n",
      "Block 21  [short_filter]  —  202M params\n",
      "   • blocks.21.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.21.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.21.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.21.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.21.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.21.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 22  [long_filter]  —  202M params\n",
      "   • blocks.22.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.22.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.22.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.22.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.22.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.22.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 23  [ssm]  —  203M params\n",
      "   • blocks.23.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.23.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.23.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.23.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.23.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.23.filter.log_poles                    (4096, 16, 1)  (66K)\n",
      "\n",
      "Block 24  [attention]  —  202M params\n",
      "   • blocks.24.inner_mha_cls.Wqkv.weight           (12288, 4096)  (50M)\n",
      "   • blocks.24.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.24.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.24.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.24.inner_mha_cls.out_proj.weight       (4096, 4096)  (17M)\n",
      "   • blocks.24.pre_norm.scale                      (4096,)  (4K)\n",
      "\n",
      "Block 25  [short_filter]  —  202M params\n",
      "   • blocks.25.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.25.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.25.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.25.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.25.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.25.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 26  [long_filter]  —  202M params\n",
      "   • blocks.26.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.26.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.26.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.26.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.26.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.26.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 27  [ssm]  —  203M params\n",
      "   • blocks.27.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.27.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.27.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.27.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.27.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.27.filter.log_poles                    (4096, 16, 1)  (66K)\n",
      "\n",
      "Block 28  [short_filter]  —  202M params\n",
      "   • blocks.28.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.28.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.28.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.28.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.28.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.28.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 29  [long_filter]  —  202M params\n",
      "   • blocks.29.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.29.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.29.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.29.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.29.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.29.filter.short_filter_weight          (12288, 1, 3)  (37K)\n",
      "\n",
      "Block 30  [ssm]  —  203M params\n",
      "   • blocks.30.projections.weight                  (12288, 4096)  (50M)\n",
      "   • blocks.30.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.30.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.30.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.30.out_filter_dense.weight             (4096, 4096)  (17M)\n",
      "   • blocks.30.filter.log_poles                    (4096, 16, 1)  (66K)\n",
      "\n",
      "Block 31  [attention]  —  202M params\n",
      "   • blocks.31.inner_mha_cls.Wqkv.weight           (12288, 4096)  (50M)\n",
      "   • blocks.31.mlp.l1.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.31.mlp.l2.weight                       (11008, 4096)  (45M)\n",
      "   • blocks.31.mlp.l3.weight                       (4096, 11008)  (45M)\n",
      "   • blocks.31.inner_mha_cls.out_proj.weight       (4096, 4096)  (17M)\n",
      "   • blocks.31.pre_norm.scale                      (4096,)  (4K)\n",
      "\n",
      "Sum over all blocks: 6B\n",
      "\n",
      "Tail (e.g., final norm etc.): 4K\n",
      "  - norm.scale                                    (4096,)  (4K)\n",
      "\n",
      "=== GRAND TOTAL CHECK ===\n",
      "Embeddings+Unembed: 4M\n",
      "Blocks total       : 6B\n",
      "Tail               : 4K\n",
      "------------------------------\n",
      "Reported Total     : 6B\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def human(n: int) -> str:\n",
    "    for unit in [\"\", \"K\", \"M\", \"B\", \"T\"]:\n",
    "        if abs(n) < 1000:\n",
    "            return f\"{n:.0f}{unit}\"\n",
    "        n /= 1000.0\n",
    "    return f\"{n:.1f}T\"\n",
    "\n",
    "def count_params_in_tensor(t: torch.Tensor) -> int:\n",
    "    try:\n",
    "        return t.numel()\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "def classify_block(block_tensors: Dict[str, torch.Tensor]) -> str:\n",
    "    \"\"\"\n",
    "    Heuristics based on keys present in the block.\n",
    "    \"\"\"\n",
    "    keys = block_tensors.keys()\n",
    "\n",
    "    # Attention\n",
    "    if any(\"inner_mha_cls.Wqkv.weight\" in k for k in keys):\n",
    "        return \"attention\"\n",
    "\n",
    "    # SSM (S4-style)\n",
    "    if any(\"filter.log_poles\" in k for k in keys) or any(\"filter.residues\" in k for k in keys):\n",
    "        return \"ssm\"\n",
    "\n",
    "    # Long filter (wide h kernel)\n",
    "    for k, v in block_tensors.items():\n",
    "        if \"filter.h\" in k and isinstance(v, torch.Tensor):\n",
    "            # shapes we've seen: (256, 1, 128) == long; (256, 1, 7) == short\n",
    "            if v.dim() >= 3 and v.shape[-1] >= 64:\n",
    "                return \"long_filter\"\n",
    "\n",
    "    # Short filter (kernel size 3 / 7)\n",
    "    if any(\"filter.short_filter_weight\" in k for k in keys):\n",
    "        return \"short_filter\"\n",
    "\n",
    "    # Generic fallback\n",
    "    return \"filter\"\n",
    "\n",
    "def summarize_state_dict(sd: Dict[str, torch.Tensor]) -> None:\n",
    "    \"\"\"\n",
    "    Print a parameter summary for the entire model and per block.\n",
    "    Assumes keys like 'blocks.N.<...>'.\n",
    "    \"\"\"\n",
    "    # Separate by area\n",
    "    top_level = {}\n",
    "    blocks = defaultdict(dict)\n",
    "    tail = {}\n",
    "\n",
    "    for k, v in sd.items():\n",
    "        # only count tensors; skip BytesIO etc.\n",
    "        if not torch.is_tensor(v):\n",
    "            continue\n",
    "\n",
    "        if k.startswith(\"blocks.\"):\n",
    "            # parse block index\n",
    "            parts = k.split(\".\")\n",
    "            try:\n",
    "                idx = int(parts[1])\n",
    "            except Exception:\n",
    "                idx = parts[1]  # fallback unusual\n",
    "            blocks[idx][k] = v\n",
    "        elif k.startswith((\"embedding_layer.\", \"unembed.\")):\n",
    "            top_level[k] = v\n",
    "        else:\n",
    "            # e.g. 'norm.scale' at the end\n",
    "            tail[k] = v\n",
    "\n",
    "    # Totals\n",
    "    total_params = 0\n",
    "    for v in sd.values():\n",
    "        if torch.is_tensor(v):\n",
    "            total_params += count_params_in_tensor(v)\n",
    "\n",
    "    print(\"=== MODEL PARAMETER SUMMARY ===\")\n",
    "    print(f\"Total tensor params: {human(total_params)}\")\n",
    "\n",
    "    # Embedding / Unembed\n",
    "    emb_params = sum(count_params_in_tensor(v) for k, v in top_level.items())\n",
    "    print(f\"Embeddings+Unembed: {human(emb_params)}\")\n",
    "    for k, v in sorted(top_level.items()):\n",
    "        print(f\"  - {k:45s} {tuple(v.shape)}  ({human(v.numel())})\")\n",
    "\n",
    "    # Per-block breakdown\n",
    "    print(\"\\n=== PER-BLOCK BREAKDOWN ===\")\n",
    "    grand_blocks = 0\n",
    "    for bi in sorted(blocks.keys(), key=lambda x: int(x) if isinstance(x, int) or str(x).isdigit() else x):\n",
    "        bdict = blocks[bi]\n",
    "        block_type = classify_block(bdict)\n",
    "        bcount = sum(count_params_in_tensor(v) for v in bdict.values())\n",
    "        grand_blocks += bcount\n",
    "        print(f\"\\nBlock {bi:>2}  [{block_type}]  —  {human(bcount)} params\")\n",
    "        # (Optional) show the big matrices first\n",
    "        big = sorted(bdict.items(), key=lambda kv: kv[1].numel(), reverse=True)\n",
    "        for k, v in big[:6]:  # top 6 largest tensors\n",
    "            print(f\"   • {k:45s} {tuple(v.shape)}  ({human(v.numel())})\")\n",
    "        # (Optional) uncomment to list all tensors in the block\n",
    "        # for k, v in big[6:]:\n",
    "        #     print(f\"     - {k:45s} {tuple(v.shape)}  ({human(v.numel())})\")\n",
    "\n",
    "    print(f\"\\nSum over all blocks: {human(grand_blocks)}\")\n",
    "\n",
    "    # Tail / final norm etc.\n",
    "    if tail:\n",
    "        tail_params = sum(count_params_in_tensor(v) for v in tail.values())\n",
    "        print(f\"\\nTail (e.g., final norm etc.): {human(tail_params)}\")\n",
    "        for k, v in sorted(tail.items()):\n",
    "            print(f\"  - {k:45s} {tuple(v.shape)}  ({human(v.numel())})\")\n",
    "\n",
    "    print(\"\\n=== GRAND TOTAL CHECK ===\")\n",
    "    print(f\"Embeddings+Unembed: {human(emb_params)}\")\n",
    "    print(f\"Blocks total       : {human(grand_blocks)}\")\n",
    "    tail_params = sum(count_params_in_tensor(v) for v in tail.values())\n",
    "    print(f\"Tail               : {human(tail_params)}\")\n",
    "    print(f\"------------------------------\")\n",
    "    print(f\"Reported Total     : {human(emb_params + grand_blocks + tail_params)}\")\n",
    "\n",
    "# ---- Usage example ----\n",
    "# ckpt = torch.load(\"evo2_7b_base.pt\", map_location=\"cpu\", weights_only=True)\n",
    "# state_dict = ckpt.get(\"state_dict\", ckpt)\n",
    "summarize_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c5783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
